import json
import warnings
from sentence_transformers import SentenceTransformer, util

# ignoring warning which is generated by sentence_transformers
warnings.filterwarnings("ignore", category=FutureWarning)

# Load model
model = SentenceTransformer("all-MiniLM-L6-v2")

# Functions
def extract_text_by_role(inputs, role):
    for entry in inputs:
        if entry.get("role") == role:
            return entry.get("context", "")
    return ""

def compute_similarity(text1, text2):
    embedding1 = model.encode(text1, convert_to_tensor=True)
    embedding2 = model.encode(text2, convert_to_tensor=True)
    score = float(util.cos_sim(embedding1, embedding2)[0][0])
    return round(score, 2)

def compute_context_precision(context_text, answer_text):
    chunk_size = 300
    chunks = [context_text[i:i+chunk_size] for i in range(0, len(context_text), chunk_size)]
    chunk_embeddings = model.encode(chunks, convert_to_tensor=True)
    answer_embedding = model.encode(answer_text, convert_to_tensor=True)
    similarities = util.cos_sim(answer_embedding, chunk_embeddings)[0]
    return round(float(similarities.max()), 2)

# Load logs
with open("logs.json", "r", encoding="utf-8") as f:
    data = json.load(f)

log_items = []
for block in data:
    if "items" in block:
        log_items.extend(block["items"])

# Evaluate
results = []
for item in log_items:
    item_id = item.get("id", "no-id")
    inputs = item.get("input", [])
    outputs = item.get("expectedOutput", [])
    llm_output = outputs[0].get("content", "") if outputs else ""

    system_text = extract_text_by_role(inputs, "system")
    user_text = extract_text_by_role(inputs, "user")

    scores = {
        "id": item_id,
        "faithfulness": compute_similarity(system_text, llm_output),
        "answer_relevancy": compute_similarity(user_text, llm_output),
        "context_precision": compute_context_precision(system_text, llm_output)
    }

    results.append(scores)

# Output scores
with open("output.json", "w", encoding="utf-8") as f:
    json.dump(results, f, indent=2)

